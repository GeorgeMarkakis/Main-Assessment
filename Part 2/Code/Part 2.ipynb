{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "pRd6t6P9suZE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cevDCg9evcWC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import sys\n",
        "import plotly.express as px\n",
        "import plotly as py\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "!pip install termcolor\n",
        "from termcolor import colored\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "py.offline.init_notebook_mode(connected = True)\n",
        "\n",
        "import datetime as dt\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read csv file**"
      ],
      "metadata": {
        "id": "HcyLYIhzszTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "df = pd.read_csv('/content/Assessment exercise dataset - orders.csv')"
      ],
      "metadata": {
        "id": "GWG7Fe7awav7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "YeF0N9xgs7DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep data for Breakfast cuisine\n",
        "breakfast_data = df.loc[df['cuisine'] == 'Breakfast']\n",
        "\n",
        "# Count orders per city in order to keep cities with > 1000 orders\n",
        "orders_per_city = breakfast_data.groupby('city').agg({'order_id':'count'})\n",
        "\n",
        "# Rename column order_id to Count_of_orders\n",
        "orders_per_city.rename(columns = {'order_id':'Count_of_orders'}, inplace = True)\n",
        "\n",
        "# Sort values based on Count_of_orders\n",
        "orders_per_city = orders_per_city.sort_values(by = 'Count_of_orders',ascending=False)\n",
        "\n",
        "# Keep cities with over 1000 orders\n",
        "orders_per_city = orders_per_city.loc[orders_per_city['Count_of_orders'] > 1000 ]\n",
        "\n",
        "# Create a dataset with cities that have > 1000 orders and cuisine = Breakfast \n",
        "final_data = pd.merge(breakfast_data,orders_per_city,on='city',how='inner')\n",
        "\n",
        "# Drop unecessary column Count_of_orders from the dataset\n",
        "final_data = final_data.drop(['Count_of_orders'], axis=1)"
      ],
      "metadata": {
        "id": "pDhNOWDGtwLL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptives\n",
        "def summary(final_data):\n",
        "    display(final_data.head())\n",
        "    print('-'*100)\n",
        "    display(final_data.info())\n",
        "    print('-'*100)\n",
        "    display(final_data.describe([0.01,0.25,0.50,0.75,0.99]))\n",
        "summary(final_data)"
      ],
      "metadata": {
        "id": "Xz2xH9vFwzxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for Missing Values\n",
        "final_data.isnull().sum() # 0 nulls\n",
        "\n",
        "# Check for the min value of column amount\n",
        "final_data.amount.min() # 0.4\n",
        "\n",
        "# Check for wrong values\n",
        "final_data.loc[final_data['amount'] <= 0 ]\n",
        "\n",
        "# Check for the max value of column amount\n",
        "final_data.amount.max() # 150.0\n",
        "\n",
        "# Shape & info of the dataset\n",
        "final_data.shape # (203389 rows, 7 columns)\n",
        "final_data.info()\n",
        "\n",
        "# Unique values for each column\n",
        "def unique_counts(final_data):\n",
        "   for i in final_data.columns:\n",
        "       count = final_data[i].nunique()\n",
        "       print(i, \": \", count)\n",
        "unique_counts(final_data)\n",
        "\n",
        "# Check for duplicates\n",
        "duplicate = final_data[final_data.duplicated()]\n",
        " \n",
        "print(\"Duplicate Rows :\") # 0 duplicates\n",
        " \n",
        "# Print the resultant Dataframe\n",
        "duplicate"
      ],
      "metadata": {
        "id": "0PXp48U2xHJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Frequency Monetary (FM) Table**"
      ],
      "metadata": {
        "id": "-KDPiDz4yuI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Frequency of orders and the Monetary value of the orders  #  -> 54496 users\n",
        "Frequency_Monetary_Table = final_data.groupby('user_id').agg({'order_id':'count','amount':'sum'})\n",
        "\n",
        "# Rename columns order_id & amount to Frequency & Monetary_Value respectively\n",
        "Frequency_Monetary_Table.rename(columns = {'order_id':'Frequency','amount':'Monetary_Value'}, inplace = True)"
      ],
      "metadata": {
        "id": "Xe3OENbEys3s"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manage Skewness and Scaling**"
      ],
      "metadata": {
        "id": "KWWdAYnw2tg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data should meet assumptions where the variables are not skewed and have the same mean and variance\n",
        "plt.figure(figsize=(12,10))\n",
        "\n",
        "# Plot Frequency distribution\n",
        "plt.subplot(3, 1, 1); sns.distplot(Frequency_Monetary_Table['Frequency'])\n",
        "\n",
        "# Plot Monetary_Value distribution\n",
        "plt.subplot(3, 1, 2); sns.distplot(Frequency_Monetary_Table['Monetary_Value'])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KKT0zoyh1VJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As we can see from above, we have to transform the data, so it has a more symmetrical form \n",
        "\n",
        "# There are some methods that we can use to manage the skewness:\n",
        "\n",
        "# 1. log transformation\n",
        "# 2. square root transformation\n",
        "# 3. box-cox transformation -> Note: We can use the transformation if and only if the variable only has positive values.\n",
        "\n",
        "def analyze_skewness(x):\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(8,8))\n",
        "    sns.distplot(Frequency_Monetary_Table[x], ax=ax[0,0])\n",
        "    sns.distplot(np.log(Frequency_Monetary_Table[x]), ax=ax[0,1])\n",
        "    sns.distplot(np.sqrt(Frequency_Monetary_Table[x]), ax=ax[1,0])\n",
        "    sns.distplot(stats.boxcox(Frequency_Monetary_Table[x])[0], ax=ax[1,1])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print('Log Transform : The skew coefficient of', Frequency_Monetary_Table[x].skew().round(2), 'to', np.log(Frequency_Monetary_Table[x]).skew().round(2))\n",
        "    print('Square Root Transform : The skew coefficient of', Frequency_Monetary_Table[x].skew().round(2), 'to', np.sqrt(Frequency_Monetary_Table[x]).skew().round(2))\n",
        "    print('Box-Cox Transform : The skew coefficient of', Frequency_Monetary_Table[x].skew().round(2), 'to', pd.Series(stats.boxcox(Frequency_Monetary_Table[x])[0]).skew().round(2))"
      ],
      "metadata": {
        "id": "U883pIrR2V-j"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_skewness('Frequency')"
      ],
      "metadata": {
        "id": "yuNPdO0S22xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_skewness('Monetary_Value')"
      ],
      "metadata": {
        "id": "hQey9Gw63Vui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the Numbers\n",
        "users_fix = pd.DataFrame()\n",
        "users_fix[\"Frequency\"] = stats.boxcox(Frequency_Monetary_Table['Frequency'])[0]\n",
        "users_fix[\"Monetary_Value\"] = stats.boxcox(Frequency_Monetary_Table['Monetary_Value'])[0]\n",
        "users_fix"
      ],
      "metadata": {
        "id": "i5c1u_nk3i2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Each variable doesnâ€™t have the same mean and variance. So we have to normalize it\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and Transform The Data\n",
        "scaler.fit(users_fix)\n",
        "users_normalized = scaler.transform(users_fix)\n",
        "\n",
        "# Assert that it has Mean 0 and Variance 1\n",
        "print(users_normalized.mean(axis = 0).round(2)) \n",
        "print(users_normalized.std(axis = 0).round(2)) "
      ],
      "metadata": {
        "id": "CFQe6OWO4OJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-MEANS Clustering**"
      ],
      "metadata": {
        "id": "8QrCXOu7D_mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering with K-means algorithm\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "K = range(1, 11)\n",
        "errors = []\n",
        "\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters = k, random_state = 42)  # random_state <> 'None' so we can have reproducible results!\n",
        "    kmeans.fit(users_normalized)\n",
        "    \n",
        "    errors.append(kmeans.inertia_)\n",
        "\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('SSE')\n",
        "sns.pointplot(x=list(range(1, 11)), y=errors)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UrCV9tOU-Pm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters = 2, init='k-means++', random_state = 42)\n",
        "kmeans.fit(users_normalized)\n",
        "\n",
        "# To evaluate the performance of this model, we'll use a metric called the silhouette score\n",
        "\n",
        "# Silhouette Coefficient or silhouette score is a metric used to calculate the goodness of a clustering technique. \n",
        "\n",
        "# Its value ranges from -1 to 1.\n",
        "\n",
        "#  1:  Means clusters are well apart from each other and clearly distinguished.\n",
        "\n",
        "#  0:  Means clusters are indifferent, or we can say that the distance between clusters is not significant.\n",
        "\n",
        "# -1:  Means clusters are assigned in the wrong way.\n",
        "\n",
        "# A higher silhouette score is indicative of a better model.\n",
        "\n",
        "print(silhouette_score(users_normalized, kmeans.labels_, metric='euclidean'))\n",
        "\n",
        "# silhouette_score:\n",
        "# 2 clusters --> 0.5706358459718361\n",
        "# 3 clusters --> 0.5319818057921492"
      ],
      "metadata": {
        "id": "i3Qw8guH5wn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign clusters to Frequency_Monetary_Table\n",
        "Frequency_Monetary_Table['Cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "rXtwQ85uDvc_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpret Cluster Result**"
      ],
      "metadata": {
        "id": "6qTCs320F0qA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column with Cluster's values interpetation\n",
        "\n",
        "Frequency_Monetary_Table.loc[(Frequency_Monetary_Table['Cluster'] == 0) , 'Customer Segment'] = 'Group B' \n",
        "Frequency_Monetary_Table.loc[(Frequency_Monetary_Table['Cluster'] == 1) , 'Customer Segment'] = 'Group A'"
      ],
      "metadata": {
        "id": "TVNBziD_1Zdi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['Frequency','Monetary_Value']\n",
        "for i in list1:\n",
        "    print(str(i)+': ')\n",
        "    ax = sns.boxplot(x=Frequency_Monetary_Table[str(i)])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2ulkyRLaQw-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MMM = Frequency_Monetary_Table.groupby('Customer Segment').agg({\n",
        "    'Frequency':'mean',\n",
        "    'Monetary_Value':['mean', 'count']}).round(1)"
      ],
      "metadata": {
        "id": "lWI4I4lID802"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MMM_median = Frequency_Monetary_Table.groupby('Cluster').agg({\n",
        "    'Frequency':'median',\n",
        "    'Monetary_Value':['median', 'count']}).round(1)"
      ],
      "metadata": {
        "id": "CDQenLsBF7q2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data to identify the distinct traits of customers in each segment\n",
        "avg_df = Frequency_Monetary_Table.groupby(['Customer Segment'], as_index=False).mean()\n",
        "for i in list1:\n",
        "     sns.set_style(style='whitegrid') \n",
        "     sns.barplot(x='Customer Segment',y=str(i),data=avg_df,palette=['royalblue','red'])\n",
        "     plt.show()"
      ],
      "metadata": {
        "id": "Cph7RaZOHR-n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}